import Foundation
import Speech
import AVFoundation
import SwiftUI

class SpeechManager: ObservableObject {
    @Published var isRecording = false
    @Published var transcript = ""
    @Published var permissionGranted = false
    
    private let speechRecognizer = SFSpeechRecognizer(locale: Locale(identifier: "ko-KR"))
    private var recognitionRequest: SFSpeechAudioBufferRecognitionRequest?
    private var recognitionTask: SFSpeechRecognitionTask?
    private let audioEngine = AVAudioEngine()
    
    private let synthesizer = AVSpeechSynthesizer()
    
    // ê¶Œí•œ ìš”ì²­
    func requestPermission() {
        SFSpeechRecognizer.requestAuthorization { authStatus in
            DispatchQueue.main.async {
                switch authStatus {
                case .authorized:
                    self.permissionGranted = true
                default:
                    self.permissionGranted = false
                    print("Speech recognition permission denied")
                }
            }
        }
    }
    
    // ë§í•˜ê¸° ì¦‰ì‹œ ì¤‘ë‹¨
    func stopSpeaking() {
        if synthesizer.isSpeaking {
            synthesizer.stopSpeaking(at: .immediate)
        }
    }
    
    // TTS ë§í•˜ê¸°
    // interrupt: trueì´ë©´ ì¦‰ì‹œ ì¤‘ë‹¨í•˜ê³  ë§í•˜ê¸°(ê¸°ë³¸ê°’), falseì´ë©´ ì´ì–´ì„œ ë§í•˜ê¸°
    func speak(_ text: String, interrupt: Bool = true) {
        if interrupt {
            stopSpeaking() // ê¸°ì¡´ ë°œí™” ì¤‘ë‹¨ í›„ ìƒˆë¡œìš´ ë°œí™”
        }
        
        let utterance = AVSpeechUtterance(string: text)
        utterance.voice = AVSpeechSynthesisVoice(language: "ko-KR")
        utterance.rate = 0.5
        
        // ì˜¤ë””ì˜¤ ì„¸ì…˜ ì„¤ì •
        let audioSession = AVAudioSession.sharedInstance()
        do {
            // .voiceChat ëª¨ë“œê°€ ì‹œìŠ¤í…œ ì•ˆì •ì„±ì´ ë†’ìŒ
            try audioSession.setCategory(.playAndRecord, mode: .voiceChat, options: [.duckOthers, .defaultToSpeaker])
            // ì„¸ì…˜ì´ ì´ë¯¸ í™œì„±í™”ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ê±°ë‚˜, ì•ˆì „í•˜ê²Œ í™œì„±í™” ì‹œë„
            if !audioSession.isOtherAudioPlaying {
                try audioSession.setActive(true, options: .notifyOthersOnDeactivation)
            }
        } catch {
            print("âš ï¸ Audio Session Setup Error in Speak (Safe): \(error.localizedDescription)")
        }
        
        synthesizer.speak(utterance)
    }
    
    // ì‹œìŠ¤í…œ íš¨ê³¼ìŒ ì¬ìƒ í—¬í¼
    private func playSound(_ systemSoundID: SystemSoundID) {
        AudioServicesPlaySystemSound(systemSoundID)
    }
    
    // ë…¹ìŒ ì‹œì‘
    func startRecording() {
        guard permissionGranted else {
            speak("ë§ˆì´í¬ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤. ì„¤ì •ì—ì„œ í—ˆìš©í•´ ì£¼ì„¸ìš”.")
            return
        }
        
        // ë“£ê¸° ì‹œì‘ íš¨ê³¼ìŒ (Begin Record)
        playSound(1113)
        
        // ë§í•˜ê¸° ì¤‘ë‹¨
        if synthesizer.isSpeaking {
            synthesizer.stopSpeaking(at: .immediate)
        }
        
        // ì´ì „ ì‘ì—… ì •ë¦¬
        if recognitionTask != nil {
            recognitionTask?.cancel()
            recognitionTask = nil
        }
        
        let audioSession = AVAudioSession.sharedInstance()
        do {
            // .voiceChat ëª¨ë“œëŠ” ì‹œìŠ¤í…œ ì˜¤ë””ì˜¤ ì—”ì§„ê³¼ ë²„í¼ ì²˜ë¦¬ê°€ ë” ë¶€ë“œëŸ½ê³  í˜¸í™˜ì„±ì´ ë†’ìŒ
            try audioSession.setCategory(.playAndRecord, mode: .voiceChat, options: [.duckOthers, .defaultToSpeaker])
            try audioSession.setActive(true, options: .notifyOthersOnDeactivation)
        } catch {
            print("Audio Session Setup Error: \(error)")
        }
        
        recognitionRequest = SFSpeechAudioBufferRecognitionRequest()
        
        let inputNode = audioEngine.inputNode
        guard let recognitionRequest = recognitionRequest else { fatalError("Unable to create request") }
        
        recognitionRequest.shouldReportPartialResults = true
        
        recognitionTask = speechRecognizer?.recognitionTask(with: recognitionRequest) { result, error in
            if let result = result {
                DispatchQueue.main.async {
                    self.transcript = result.bestTranscription.formattedString // ì¸ì‹ëœ í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸
                }
            }
            
            if error != nil || (result?.isFinal ?? false) {
                // ë‚´ë¶€ í˜¸ì¶œì´ ì•„ë‹Œ ê²½ìš°ì—ë§Œ stopRecording í˜¸ì¶œ (ë¬´í•œ ë£¨í”„ ë°©ì§€)
                if self.isRecording { self.stopRecording() }
            }
        }
        
        let recordingFormat = inputNode.outputFormat(forBus: 0)
        // ë²„í¼ ì‚¬ì´ì¦ˆë¥¼ 4096ìœ¼ë¡œ ìƒí–¥í•˜ì—¬ í•˜ë“œì›¨ì–´ ê²½ê³  ë¡œê·¸(mDataByteSize 0) ë°œìƒ ë¹ˆë„ ê°ì†Œ
        inputNode.installTap(onBus: 0, bufferSize: 4096, format: recordingFormat) { (buffer, when) in
            // ë°ì´í„° ìœ ë¬´ë¥¼ ì—„ê²©íˆ ì²´í¬
            if buffer.frameLength > 0, 
               let data = buffer.audioBufferList.pointee.mBuffers.mData,
               buffer.audioBufferList.pointee.mBuffers.mDataByteSize > 0 {
                self.recognitionRequest?.append(buffer)
            }
        }
        
        // ì•ˆì „í•œ ì—”ì§„ ì¬ì‹œì‘: ì´ë¯¸ ì‹¤í–‰ ì¤‘ì´ë©´ ì¤‘ì§€ í›„ ì‹œì‘ (ë²„í¼ ì¶©ëŒ ë°©ì§€)
        if audioEngine.isRunning {
            audioEngine.stop()
            audioEngine.inputNode.removeTap(onBus: 0)
        }
        
        audioEngine.prepare()
        do {
            try audioEngine.start()
            isRecording = true
            transcript = "" 
            print("ğŸ™ï¸ Audio Engine Started Successfully")
            
            // ì‹œì‘ í–…í‹± í”¼ë“œë°±
            let generator = UIImpactFeedbackGenerator(style: .medium)
            generator.impactOccurred()
        } catch {
            print("âŒ Audio Engine Start Error: \(error.localizedDescription)")
        }
    }
    
    // ë…¹ìŒ ì¤‘ì§€
    func stopRecording() {
        if isRecording {
            audioEngine.stop()
            inputNodeRemoveTap()
            recognitionRequest?.endAudio()
            isRecording = false
            
            // ì¢…ë£Œ íš¨ê³¼ìŒ (End Record)
            playSound(1114)
            
            print("Final Transcript: \(self.transcript)")
        }
    }
    
    private func inputNodeRemoveTap() {
        // íƒ­ ì œê±° ì‹œ ì•ˆì „ ì¥ì¹˜
        let inputNode = audioEngine.inputNode
        inputNode.removeTap(onBus: 0)
    }
}
