import Foundation
import Speech
import AVFoundation
import SwiftUI
import AudioToolbox

class SpeechManager: ObservableObject {
    @Published var isRecording = false
    @Published var transcript = ""
    @Published var permissionGranted = false
    
    private let speechRecognizer = SFSpeechRecognizer(locale: Locale(identifier: "ko-KR"))
    private var recognitionRequest: SFSpeechAudioBufferRecognitionRequest?
    private var recognitionTask: SFSpeechRecognitionTask?
    private let audioEngine = AVAudioEngine()
    
    private let synthesizer = AVSpeechSynthesizer()
    
    // ê¶Œí•œ ìš”ì²­
    func requestPermission() {
        SFSpeechRecognizer.requestAuthorization { authStatus in
            DispatchQueue.main.async {
                switch authStatus {
                case .authorized:
                    self.permissionGranted = true
                default:
                    self.permissionGranted = false
                    print("Speech recognition permission denied")
                }
            }
        }
    }
    
    // ë§í•˜ê¸° ì¦‰ì‹œ ì¤‘ë‹¨
    func stopSpeaking() {
        if synthesizer.isSpeaking {
            synthesizer.stopSpeaking(at: .immediate)
        }
    }
    
    // TTS ë§í•˜ê¸°
    // interrupt: trueì´ë©´ ì¦‰ì‹œ ì¤‘ë‹¨í•˜ê³  ë§í•˜ê¸°(ê¸°ë³¸ê°’), falseì´ë©´ ì´ì–´ì„œ ë§í•˜ê¸°
    func speak(_ text: String, interrupt: Bool = true) {
        // VoiceOverê°€ í™œì„±í™”ë˜ì–´ ìˆìœ¼ë©´ ì•± TTS ì‚¬ìš© ì•ˆ í•¨ (ì¶©ëŒ ë°©ì§€)
        // VoiceOverê°€ ì´ë¯¸ í™”ë©´ ìš”ì†Œë¥¼ ì½ì–´ì£¼ë¯€ë¡œ ì¤‘ë³µ ë°œí™” ë°©ì§€
        if UIAccessibility.isVoiceOverRunning {
            // VoiceOver ì‚¬ìš©ìì—ê²ŒëŠ” accessibilityAnnouncementë¡œ ì „ë‹¬
            UIAccessibility.post(notification: .announcement, argument: text)
            return
        }
        
        if interrupt {
            stopSpeaking() // ê¸°ì¡´ ë°œí™” ì¤‘ë‹¨ í›„ ìƒˆë¡œìš´ ë°œí™”
        }
        
        let utterance = AVSpeechUtterance(string: text)
        utterance.voice = AVSpeechSynthesisVoice(language: "ko-KR")
        
        // Quick Win 2: ì‚¬ìš©ì ì„¤ì •ì— ë”°ë¥¸ TTS ì†ë„ ì ìš©
        let savedRate = UserDefaults.standard.float(forKey: "speechRate")
        utterance.rate = savedRate > 0 ? savedRate : 0.5 // ê¸°ë³¸ê°’ 0.5
        
        // ì˜¤ë””ì˜¤ ì„¸ì…˜ ì„¤ì •
        let audioSession = AVAudioSession.sharedInstance()
        do {
            // .voiceChat ëª¨ë“œê°€ ì‹œìŠ¤í…œ ì•ˆì •ì„±ì´ ë†’ìŒ
            try audioSession.setCategory(.playAndRecord, mode: .voiceChat, options: [.duckOthers, .defaultToSpeaker])
            // ì„¸ì…˜ì´ ì´ë¯¸ í™œì„±í™”ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ê±°ë‚˜, ì•ˆì „í•˜ê²Œ í™œì„±í™” ì‹œë„
            if !audioSession.isOtherAudioPlaying {
                try audioSession.setActive(true, options: .notifyOthersOnDeactivation)
            }
        } catch {
            print("âš ï¸ Audio Session Setup Error in Speak (Safe): \(error.localizedDescription)")
        }
        
        synthesizer.speak(utterance)
    }
    
    // ì‹œìŠ¤í…œ íš¨ê³¼ìŒ ì¬ìƒ í—¬í¼
    private func playSound(_ systemSoundID: SystemSoundID) {
        AudioServicesPlaySystemSound(systemSoundID)
    }
    
    // ë…¹ìŒ ì‹œì‘
    func startRecording() {
        guard permissionGranted else {
            speak("ë§ˆì´í¬ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤. ì„¤ì •ì—ì„œ í—ˆìš©í•´ ì£¼ì„¸ìš”.")
            return
        }
        
        // ë“£ê¸° ì‹œì‘ íš¨ê³¼ìŒ (Begin Record)
        playSound(1113)
        
        // ë§í•˜ê¸° ì¤‘ë‹¨
        if synthesizer.isSpeaking {
            synthesizer.stopSpeaking(at: .immediate)
        }
        
        // ì´ì „ ì‘ì—… ì •ë¦¬
        if recognitionTask != nil {
            recognitionTask?.cancel()
            recognitionTask = nil
        }
        
        let audioSession = AVAudioSession.sharedInstance()
        do {
            // .voiceChat ëª¨ë“œëŠ” ì‹œìŠ¤í…œ ì˜¤ë””ì˜¤ ì—”ì§„ê³¼ ë²„í¼ ì²˜ë¦¬ê°€ ë” ë¶€ë“œëŸ½ê³  í˜¸í™˜ì„±ì´ ë†’ìŒ
            try audioSession.setCategory(.playAndRecord, mode: .voiceChat, options: [.duckOthers, .defaultToSpeaker])
            try audioSession.setActive(true, options: .notifyOthersOnDeactivation)
        } catch {
            print("Audio Session Setup Error: \(error)")
        }
        
        recognitionRequest = SFSpeechAudioBufferRecognitionRequest()
        
        let inputNode = audioEngine.inputNode
        guard let recognitionRequest = recognitionRequest else { fatalError("Unable to create request") }
        
        recognitionRequest.shouldReportPartialResults = true
        
        recognitionTask = speechRecognizer?.recognitionTask(with: recognitionRequest) { result, error in
            if let result = result {
                DispatchQueue.main.async {
                    self.transcript = result.bestTranscription.formattedString // ì¸ì‹ëœ í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸
                }
            }
            
            if error != nil || (result?.isFinal ?? false) {
                // ë‚´ë¶€ í˜¸ì¶œì´ ì•„ë‹Œ ê²½ìš°ì—ë§Œ stopRecording í˜¸ì¶œ (ë¬´í•œ ë£¨í”„ ë°©ì§€)
                if self.isRecording { self.stopRecording() }
            }
        }
        
        let recordingFormat = inputNode.outputFormat(forBus: 0)
        // ë²„í¼ ì‚¬ì´ì¦ˆë¥¼ 4096ìœ¼ë¡œ ìƒí–¥í•˜ì—¬ í•˜ë“œì›¨ì–´ ê²½ê³  ë¡œê·¸(mDataByteSize 0) ë°œìƒ ë¹ˆë„ ê°ì†Œ
        inputNode.installTap(onBus: 0, bufferSize: 4096, format: recordingFormat) { (buffer, when) in
            // ë°ì´í„° ìœ ë¬´ë¥¼ ì—„ê²©íˆ ì²´í¬
            if buffer.frameLength > 0, 
               let data = buffer.audioBufferList.pointee.mBuffers.mData,
               buffer.audioBufferList.pointee.mBuffers.mDataByteSize > 0 {
                self.recognitionRequest?.append(buffer)
            }
        }
        
        // ì•ˆì „í•œ ì—”ì§„ ì¬ì‹œì‘: ì´ë¯¸ ì‹¤í–‰ ì¤‘ì´ë©´ ì¤‘ì§€ í›„ ì‹œì‘ (ë²„í¼ ì¶©ëŒ ë°©ì§€)
        if audioEngine.isRunning {
            audioEngine.stop()
            audioEngine.inputNode.removeTap(onBus: 0)
        }
        
        audioEngine.prepare()
        do {
            try audioEngine.start()
            isRecording = true
            transcript = "" 
            print("ğŸ™ï¸ Audio Engine Started Successfully")
            
            // ì‹œì‘ í–…í‹± í”¼ë“œë°±
            let generator = UIImpactFeedbackGenerator(style: .medium)
            generator.impactOccurred()
        } catch {
            print("âŒ Audio Engine Start Error: \(error.localizedDescription)")
        }
    }
    
    // ë…¹ìŒ ì¤‘ì§€
    func stopRecording() {
        if isRecording {
            audioEngine.stop()
            inputNodeRemoveTap()
            recognitionRequest?.endAudio()
            isRecording = false
            
            // ì¢…ë£Œ íš¨ê³¼ìŒ (End Record)
            playSound(1114)
            
            print("Final Transcript: \(self.transcript)")
        }
    }
    
    private func inputNodeRemoveTap() {
        // íƒ­ ì œê±° ì‹œ ì•ˆì „ ì¥ì¹˜
        let inputNode = audioEngine.inputNode
        inputNode.removeTap(onBus: 0)
    }
}

// ì‚¬ìš´ë“œ ë§¤ë‹ˆì € (UI í”¼ë“œë°± í†µí•©: ì‚¬ìš´ë“œ + í–…í‹±)
class SoundManager {
    static let shared = SoundManager()
    
    private init() {
        // í–…í‹± ì—”ì§„ ì‚¬ì „ ì¤€ë¹„ (ì§€ì—° ìµœì†Œí™”)
        prepareHapticGenerators()
    }
    
    // ì‚¬ì „ ì¤€ë¹„ëœ í–…í‹± ì œë„ˆë ˆì´í„°ë“¤ (ì„±ëŠ¥ ìµœì í™”)
    private let heavyGenerator = UIImpactFeedbackGenerator(style: .heavy)
    private let rigidGenerator = UIImpactFeedbackGenerator(style: .rigid)
    private let softGenerator = UIImpactFeedbackGenerator(style: .soft)
    private let notificationGenerator = UINotificationFeedbackGenerator()
    
    private func prepareHapticGenerators() {
        heavyGenerator.prepare()
        rigidGenerator.prepare()
        softGenerator.prepare()
        notificationGenerator.prepare()
    }
    
    enum SoundType {
        case click          // ì¼ë°˜ í´ë¦­
        case tabSelection   // íƒ­ ë³€ê²½
        case recordingStart // ë…¹ìŒ ì‹œì‘
        case recordingEnd   // ë…¹ìŒ ì¢…ë£Œ
        case success        // ì„±ê³µ (ê²½ë¡œ/ì¥ì†Œ ë°œê²¬)
        case failure        // ì‹¤íŒ¨/ì—ëŸ¬
        case finding        // íƒìƒ‰ ì¤‘ (ë°©í–¥ ê°ì§€) - ê°€ì¥ ì¤‘ìš”!
    }
    
    func play(_ type: SoundType) {
        // 1. ì‚¬ìš´ë“œ ì¬ìƒ (ë¶€ë“œëŸ½ê³  ëª…í™•í•œ ì‹œìŠ¤í…œ ì‚¬ìš´ë“œ)
        var soundID: SystemSoundID = 0
        switch type {
        case .click:          soundID = 1104  // Tock (ë¶€ë“œëŸ¬ìš´ í´ë¦­)
        case .tabSelection:   soundID = 1103  // Tink (ê°€ë²¼ìš´ íƒ­)
        case .recordingStart: soundID = 1113  // Begin Recording (í‘œì¤€)
        case .recordingEnd:   soundID = 1114  // End Recording (í‘œì¤€)
        case .success:        soundID = 1001  // Mail Sent (ë¶€ë“œëŸ¬ìš´ ì„±ê³µ)
        case .failure:        soundID = 1053  // ë¶€ë“œëŸ¬ìš´ ì•Œë¦¼ìŒ
        case .finding:        soundID = 1104  // Tock (ë¶€ë“œëŸ½ì§€ë§Œ ëª…í™•)
        }
        AudioServicesPlaySystemSound(soundID)
        
        // 2. ê°•í™”ëœ í–…í‹± í”¼ë“œë°±
        let hapticBlock = { [self] in
            switch type {
            case .click:
                // í´ë¦­: Heavy (ê°•í•¨)
                heavyGenerator.impactOccurred(intensity: 0.8)
                
            case .tabSelection:
                // íƒ­ ë³€ê²½: Heavy + ì•½ê°„ ë’¤ì— Soft (ì´ì¤‘ í–…í‹±)
                heavyGenerator.impactOccurred(intensity: 1.0)
                DispatchQueue.main.asyncAfter(deadline: .now() + 0.08) { [self] in
                    softGenerator.impactOccurred(intensity: 0.6)
                }
                
            case .success:
                // ì„±ê³µ: Success ì•Œë¦¼ + Heavy (ì´ì¤‘ í”¼ë“œë°±)
                notificationGenerator.notificationOccurred(.success)
                DispatchQueue.main.asyncAfter(deadline: .now() + 0.1) { [self] in
                    heavyGenerator.impactOccurred(intensity: 1.0)
                }
                
            case .failure:
                // ì‹¤íŒ¨: Error ì•Œë¦¼ (ê°•í•œ ê²½ê³ )
                notificationGenerator.notificationOccurred(.error)
                DispatchQueue.main.asyncAfter(deadline: .now() + 0.15) { [self] in
                    notificationGenerator.notificationOccurred(.error)
                }
                
            case .recordingStart:
                // ë…¹ìŒ ì‹œì‘: Heavy + Rigid (ê°•ë ¥í•œ ì‹œì‘ ì‹ í˜¸)
                heavyGenerator.impactOccurred(intensity: 1.0)
                DispatchQueue.main.asyncAfter(deadline: .now() + 0.1) { [self] in
                    rigidGenerator.impactOccurred(intensity: 1.0)
                }
                
            case .recordingEnd:
                // ë…¹ìŒ ì¢…ë£Œ: Rigid x2 (í™•ì‹¤í•œ ì¢…ë£Œ ì‹ í˜¸)
                rigidGenerator.impactOccurred(intensity: 1.0)
                DispatchQueue.main.asyncAfter(deadline: .now() + 0.12) { [self] in
                    rigidGenerator.impactOccurred(intensity: 0.8)
                }
                
            case .finding:
                // ğŸ”¥ ë””ì§€í„¸ì¼€ì¸ íƒìƒ‰: ê°€ì¥ ê°•ë ¥í•œ 3ë‹¨ í–…í‹± (í™•ì‹¤í•œ ì¸ì§€!)
                heavyGenerator.impactOccurred(intensity: 1.0)
                DispatchQueue.main.asyncAfter(deadline: .now() + 0.08) { [self] in
                    rigidGenerator.impactOccurred(intensity: 1.0)
                }
                DispatchQueue.main.asyncAfter(deadline: .now() + 0.16) { [self] in
                    heavyGenerator.impactOccurred(intensity: 0.9)
                }
            }
            
            // ë‹¤ìŒ í˜¸ì¶œì„ ìœ„í•´ ì œë„ˆë ˆì´í„° ì¤€ë¹„ (ì§€ì—° ìµœì†Œí™”)
            prepareHapticGenerators()
        }
        
        if Thread.isMainThread {
            hapticBlock()
        } else {
            DispatchQueue.main.async(execute: hapticBlock)
        }
    }
}
